name: Update Forum Data

on:
  schedule:
    - cron: '0 */6 * * *'  # Run every 6 hours
  workflow_dispatch:  # Allow manual triggering

jobs:
  update-data:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2
      
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install forum-dl beautifulsoup4 requests
          
      - name: Create scraper directory
        run: mkdir -p scraper
      
      - name: Create or update scraper script
        run: |
          cat > scraper/phpbb_scraper.py << 'EOF'
          import requests
          from bs4 import BeautifulSoup
          import json
          import os
          import re
          import time
          import random
          from datetime import datetime

          class PhpBBScraper:
              def __init__(self, base_url, output_file):
                  self.base_url = base_url
                  self.output_file = output_file
                  self.session = requests.Session()
                  self.session.headers.update({
                      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                  })
                  self.categories = []
                  self.forums = []
                  self.topics = []
                  self.posts = []
              
              def scrape(self):
                  """Main scraping method that orchestrates the process"""
                  print(f"Starting to scrape {self.base_url}")
                  
                  # Scrape the index page to get categories and forums
                  self.scrape_index()
                  
                  # Limit the number of forums to scrape (for testing)
                  forums_to_scrape = self.forums[:5]  # Only scrape the first 5 forums
                  
                  # Scrape each forum to get topics
                  for forum in forums_to_scrape:
                      self.scrape_forum(forum['id'], forum['url'])
                      time.sleep(random.uniform(1, 3))  # Random delay between requests
                  
                  # Limit the number of topics to scrape (for testing)
                  topics_to_scrape = self.topics[:10]  # Only scrape the first 10 topics
                  
                  # Scrape each topic to get posts
                  for topic in topics_to_scrape:
                      self.scrape_topic(topic['id'], topic['url'])
                      time.sleep(random.uniform(1, 3))  # Random delay between requests
                  
                  # Save the scraped data
                  self.save_data()
                  
                  print(f"Scraping completed. Data saved to {self.output_file}")
              
              def scrape_index(self):
                  """Scrape the forum index page to get categories and forums"""
                  response = self.session.get(self.base_url)
                  soup = BeautifulSoup(response.text, 'html.parser')
                  
                  # Extract categories and forums based on phpBB structure
                  # This is a simplified example and might need adjustment for your specific forum
                  categories = soup.select('.forabg')
                  
                  for idx, category in enumerate(categories):
                      category_name = category.select_one('.header .header-title a').text.strip()
                      category_id = f"cat_{idx + 1}"
                      
                      category_data = {
                          'id': category_id,
                          'name': category_name,
                          'forums': []
                      }
                      
                      forums = category.select('li.row')
                      for forum_idx, forum in enumerate(forums):
                          forum_title_elem = forum.select_one('.forumtitle')
                          if not forum_title_elem:
                              continue
                              
                          forum_title = forum_title_elem.text.strip()
                          forum_url = forum_title_elem['href']
                          if not forum_url.startswith('http'):
                              forum_url = self.base_url + '/' + forum_url.lstrip('/')
                          
                          forum_desc_elem = forum.select_one('.forum-description')
                          forum_desc = forum_desc_elem.text.strip() if forum_desc_elem else ""
                          
                          forum_id = f"forum_{idx +
